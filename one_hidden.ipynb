{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Define neural network'\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        t = F.sigmoid(self.fc1(x))\n",
    "        y = F.sigmoid(self.fc2(t))\n",
    "        return t, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Change to n-spherical coordinates'\n",
    "\n",
    "def rand_n_sphere(r, alpha):\n",
    "    \"\"\"alpha: the n-1 values between [0,\\pi) and last one between [0,2\\pi)\n",
    "    \"\"\"\n",
    "    x = np.zeros(len(alpha) + 1)\n",
    "    s = 1\n",
    "    for e, a in enumerate(alpha):\n",
    "        x[e] = s * np.cos(a)\n",
    "        s *= np.sin(a)\n",
    "    x[len(alpha)] = s\n",
    "    return x*r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Initialize x_s randomly on n-sphere'\n",
    "\n",
    "n = 10                #Input dimension\n",
    "input_size = 5000     #Number of samples (test + train)\n",
    "\n",
    "x = np.zeros((input_size, n))\n",
    "y = np.zeros((input_size,))\n",
    "\n",
    "for i in range(input_size):\n",
    "    alpha = np.random.rand(n - 1) * np.pi\n",
    "    alpha[-1] = 2* alpha[-1]\n",
    "\n",
    "    x[i,:] = rand_n_sphere(1, alpha)\n",
    "    \n",
    "#    if x[i,0] > 0 and x[i,1] < 0.5 and x[i,1] > -0.2 or x[i,2] < -0.4:\n",
    "#        y[i] = 1            \n",
    "    \n",
    "#y = np.random.randint(1, size = input_size) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot received an invalid combination of arguments - got (\u001b[31;1mnumpy.ndarray\u001b[0m), but expected (torch.FloatTensor tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-a9a462332e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m'Visualize first 3 dimensions of x, y is the color'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-a9a462332e3d>\u001b[0m in \u001b[0;36mrandom_perceptron\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dot received an invalid combination of arguments - got (\u001b[31;1mnumpy.ndarray\u001b[0m), but expected (torch.FloatTensor tensor)"
     ]
    }
   ],
   "source": [
    "'Perceptron classification, i.e. create y vector'\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(x))\n",
    "\n",
    "def random_perceptron(x):\n",
    "    W = np.random.rand(n, 1)\n",
    "    b = np.random.rand(1)\n",
    "\n",
    "    return sigmoid(x.dot(W) + b)\n",
    "\n",
    "y = random_perceptron(x)\n",
    "\n",
    "'Visualize first 3 dimensions of x, y is the color'\n",
    "\n",
    "fig = plt.figure(2)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x[:,0], x[:,1], x[:,2], c = [(float(i),float(i)*0.3,0.5) for i in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Convert numpy to torch tensors'\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "x,y = x.type(torch.FloatTensor),y.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Given histogram matrix (num of hidden layers) x (num bins)'\n",
    "'gives mutual information as sum on of the entropy of each unit in hidden layer'\n",
    "\n",
    "def mutual_info(hist, nb_units):\n",
    "    MI = 0\n",
    "    for i in range(nb_units):\n",
    "        p = hist[i,:] / np.sum(np.sum(hist[i,:])) + 1e-8 # add sth small to avoid Nan in log\n",
    "        MI -= np.sum(np.multiply(p, np.log(p)))\n",
    "        \n",
    "    return MI\n",
    "\n",
    "def plot_hist(hist, nb_bins, nb_units):\n",
    "    for i in range(nb_units):\n",
    "        plt.figure(i)\n",
    "        plt.title(str(i))\n",
    "        plt.bar(range(nb_bins), hist[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5843410221859813\n",
      "1 0.5653466526418924\n",
      "2 0.5566060291603208\n",
      "3 0.5480946712195873\n",
      "4 0.5395619673654437\n",
      "5 0.5309836836531758\n",
      "6 0.5223433803766966\n",
      "7 0.5136270606890321\n",
      "8 0.5048230206593871\n",
      "9 0.49592186976224184\n",
      "10 0.4869163716211915\n",
      "11 0.4778015725314617\n",
      "12 0.4685748890042305\n",
      "13 0.45923591684550047\n",
      "14 0.44978642649948597\n",
      "15 0.4402304831892252\n",
      "16 0.4305743360891938\n",
      "17 0.4208262450993061\n",
      "18 0.41099654417485\n",
      "19 0.40109748393297195\n",
      "20 0.39114309567958117\n",
      "21 0.3811490274965763\n",
      "22 0.3711322918534279\n",
      "23 0.3611112767830491\n",
      "24 0.351105242036283\n",
      "25 0.3411341803148389\n",
      "26 0.33121875673532486\n",
      "27 0.3213797090575099\n",
      "28 0.3116377554833889\n",
      "29 0.3020133157260716\n",
      "30 0.2925262078642845\n",
      "31 0.28319542622193694\n",
      "32 0.2740389686077833\n",
      "33 0.26507346192374825\n",
      "34 0.25631403317674994\n",
      "35 0.2477742936462164\n",
      "36 0.23946616239845753\n",
      "37 0.23139969259500504\n",
      "38 0.223583091981709\n",
      "39 0.2160228006541729\n",
      "40 0.20872323773801327\n",
      "41 0.20168722281232476\n",
      "42 0.19491578452289104\n",
      "43 0.18840833706781268\n",
      "44 0.18216284178197384\n",
      "45 0.17617587745189667\n",
      "46 0.1704428056254983\n",
      "47 0.16495790285989642\n",
      "48 0.15971455909311771\n",
      "49 0.15470534889027476\n"
     ]
    }
   ],
   "source": [
    "'Training'\n",
    "\n",
    "train_input, train_target = Variable(x[:int(input_size*0.7), :]), Variable(y[:int(input_size*0.7)])\n",
    "\n",
    "nb_hidden = 15\n",
    "nb_bins = 20      #Bins for mutual information estimation\n",
    "nb_epochs = 50\n",
    "\n",
    "\n",
    "model, criterion = Net(nb_hidden), nn.MSELoss()\n",
    "eta, mini_batch_size = 1e-1, 100\n",
    "\n",
    "MI_hidden = np.zeros((nb_epochs,))\n",
    "MI_output = np.zeros((nb_epochs,))\n",
    "\n",
    "for e in range(0, nb_epochs):\n",
    "    sum_loss = 0\n",
    "    hist_hidden = np.zeros((nb_hidden, nb_bins)) #create histogram to store occurrance of each hidden node value in each bin\n",
    "    hist_output = np.zeros((1, nb_bins)) \n",
    "    \n",
    "    # We do this with mini-batches\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):\n",
    "        t, output = model.forward(train_input.narrow(0, b, mini_batch_size))\n",
    "        loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "        sum_loss = sum_loss + loss.data[0]\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in model.parameters():\n",
    "            p.data.sub_(eta * p.grad.data)\n",
    "        \n",
    "        #Divide output of hidden layer into bins for one epoch, hist has 20\n",
    "        hist_hidden += np.array([np.histogram(s, bins = nb_bins)[0] for s in t.data.numpy().T])\n",
    "        hist_output += np.array(np.histogram(output.data.numpy(), bins = nb_bins)[0])\n",
    "        \n",
    "    MI_hidden[e] = mutual_info(hist_hidden, nb_hidden)\n",
    "    MI_output[e] = mutual_info(hist_output, 1)\n",
    "    \n",
    "    print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.83542935 2.89873213 2.92529648 2.94096339 2.9503379  2.9516065\n",
      " 2.9495547  2.94762479 2.94887964 2.94835214 2.94904986 2.94683945\n",
      " 2.94790986 2.9462578  2.944325   2.94211905 2.93936065 2.93819198\n",
      " 2.93817756 2.93714008 2.93548289 2.93376429 2.9331386  2.93278075\n",
      " 2.93172689 2.93100767 2.93145614 2.93130626 2.9310747  2.92951937\n",
      " 2.9287634  2.92785317 2.9259314  2.92604203 2.92595561 2.92543485\n",
      " 2.92491072 2.92485551 2.92446399 2.92461491 2.92488096 2.924474\n",
      " 2.92431046 2.92346839 2.92306123 2.92260824 2.92235279 2.92201512\n",
      " 2.92167797 2.92231442]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b5e2dc128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'Plot last epoch histograms for MI'\n",
    "\n",
    "plot_hist(hist_output, nb_bins, 1)\n",
    "print(MI_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.004403756931424141 2.570143461227417\n"
     ]
    }
   ],
   "source": [
    "'Computing loss on test data'\n",
    "\n",
    "test_input, test_target = Variable(x[int(input_size*0.7):, :]), Variable(y[int(input_size*0.7):])\n",
    "\n",
    "_, output = model.forward(test_input)\n",
    "\n",
    "mse = (torch.norm(output - test_target)).mean()\n",
    "loss = criterion(output, test_target)\n",
    "\n",
    "print(\"MSE = \", float(loss), float(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Other n-sphere_OLD'\n",
    "\n",
    "n = 4\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for i in range(1000):\n",
    "    color = 'g'\n",
    "    alpha = np.pi * np.random.rand(n - 2)\n",
    "    alpha[-1] = 2* alpha[-1]\n",
    "\n",
    "    x = rand_n_sphere(1, alpha)\n",
    "        \n",
    "    if x[0] > 0 and x[1] < 0.5 and x[1] > -0.2 or x[2] < -0.4: \n",
    "        color = \"b\" \n",
    "    ax.scatter(x[0], x[1], x[2], c = (0.6,0,y))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
